{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <center> Data Downloads and Embedding </center>\n",
    " \n",
    " This notebook contains information on the source of all natural language and music data used in the paper, along with code to embed the raw data as a real-valued multivariate time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural language data\n",
    "\n",
    "#### 0. GloVe embeddings\n",
    "\n",
    "We embed the natural language data using the 200d pre-trained GloVe embeddings, which can be downloaded at http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "Once downloaded, use the following code to load the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print(\"Done. {} words loaded!\".format(len(model)))\n",
    "    return model\n",
    "\n",
    "glove200 = None # replace with path to glove.6B.200d.txt file\n",
    "gl_embed = loadGloveModel(glove200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Penn TreeBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools to parse Penn TreeBank data, adapted from the PyTorch language modeling tutorial\n",
    "class Dictionary:\n",
    "    def __init__(self):\n",
    "        self.word_to_ix = {}\n",
    "        self.ix_to_word = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ix_to_word)\n",
    "    \n",
    "    def add_word(self,word):\n",
    "        if word not in self.word_to_ix:\n",
    "            self.ix_to_word.append(word)\n",
    "            self.word_to_ix[word] = len(self.ix_to_word)-1\n",
    "        return self.word_to_ix[word]\n",
    "    \n",
    "class Corpus:\n",
    "    def __init__(self,path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path,'ptb.train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path,'ptb.valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path,'ptb.test.txt'))\n",
    "        \n",
    "    def tokenize(self,path):\n",
    "        # first add words to dictionary\n",
    "        with open(path) as f:\n",
    "            tokens = 0\n",
    "            for line in f:\n",
    "                words = line.split()+['<eos>']\n",
    "                tokens += len(words)\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "        \n",
    "        # then return tokenized file content\n",
    "        with open(path) as f:\n",
    "            ids = torch.LongTensor(tokens)\n",
    "            token = 0\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                for word in words:\n",
    "                    ids[token] = self.dictionary.word_to_ix[word]\n",
    "                    token += 1\n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb_path = None # replace with path to Penn TreeBank train / validation / test .txt files\n",
    "corpus = Corpus(ptb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for embedding\n",
    "print('Embedding... ')\n",
    "train_emb = np.zeros((200,len(corpus.train)))\n",
    "count = 0\n",
    "for t in range(len(corpus.train)):\n",
    "    wd = corpus.dictionary.ix_to_word[corpus.train[t]]\n",
    "    if wd == '<eos>':\n",
    "        wd = 'eos'\n",
    "    train_emb[:,t] = gl_embed.get(wd,gl_embed['unk'])\n",
    "    if gl_embed.get(wd,gl_embed['unk']) is gl_embed['unk']:\n",
    "        count += 1\n",
    "train_emb = torch.FloatTensor(train_emb).t().cuda() # shape to T x k\n",
    "print('... train (shape {} x {}), unk count: {}'.format(train_emb.shape[0],train_emb.shape[1],count))  \n",
    "\n",
    "valid_emb = np.zeros((200,len(corpus.valid)))\n",
    "count = 0\n",
    "for t in range(len(corpus.valid)):\n",
    "    wd = corpus.dictionary.ix_to_word[corpus.valid[t]]\n",
    "    if wd == '<eos>':\n",
    "        wd = 'eos'\n",
    "    valid_emb[:,t] = gl_embed.get(wd,gl_embed['unk'])\n",
    "    if gl_embed.get(wd,gl_embed['unk']) is gl_embed['unk']:\n",
    "        count += 1\n",
    "valid_emb = torch.FloatTensor(valid_emb).t().cuda()\n",
    "print('... valid (shape {} x {}), unk count: {}'.format(valid_emb.shape[0],valid_emb.shape[1],count)) \n",
    "\n",
    "test_emb = np.zeros((200,len(corpus.test)))\n",
    "count = 0\n",
    "for t in range(len(corpus.test)):\n",
    "    wd = corpus.dictionary.ix_to_word[corpus.test[t]]\n",
    "    if wd == '<eos>':\n",
    "        wd = 'eos'\n",
    "    test_emb[:,t] = gl_embed.get(wd,gl_embed['unk'])\n",
    "    if gl_embed.get(wd,gl_embed['unk']) is gl_embed['unk']:\n",
    "        count += 1\n",
    "test_emb = torch.FloatTensor(test_emb).t().cuda()\n",
    "print('... test (shape {} x {}), unk count: {}'.format(test_emb.shape[0],test_emb.shape[1],count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. King James Bible\n",
    "\n",
    "The text is available from Project Gutenberg at http://www.gutenberg.org/cache/epub/10/pg10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This pre-processing step performs the following:\n",
    "\n",
    "- ignore 32 lines of Gutenberg intro at start\n",
    "- strip chapter:verse from line where applicable\n",
    "- send to lower case\n",
    "- keep punctuation but separate from text with whitespace '''\n",
    "\n",
    "path_to_bible = None # replace with path to bible txt file\n",
    "\n",
    "with open(path_to_bible) as f:\n",
    "    text = []\n",
    "    i=0\n",
    "    line_count = 0\n",
    "    word_count = 0\n",
    "    for line in f:\n",
    "        line_count += 1\n",
    "        word_count += len(line.split())\n",
    "        if line_count>32:\n",
    "            if len(line.rstrip())>0:\n",
    "                text += [re.sub(r'([a-z]+)([:,?!.$])',r'\\1 \\2',re.sub('\\d+:\\d+ ','',line.lower().rstrip()))]\n",
    "    print('total lines: {}'.format(line_count))\n",
    "    print('total words: {}'.format(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the data\n",
    "bible_emb = np.zeros((200,len(full_text)))\n",
    "for t in range(len(full_text)):\n",
    "    bible_emb[:,t] = gl_embed.get(full_text[t],gl_embed['unk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Facebook bAbI: Children's book test\n",
    "\n",
    "The data can be downloaded from http://www.thespermwhale.com/jaseweston/babi/CBTest.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdata =  None # path to downloaded cbt_train.txt file\n",
    "\n",
    "# read individual books from training set, store separately\n",
    "with open(cbdata) as f:\n",
    "    fb_text = {}\n",
    "    i=0\n",
    "    line_count = 0\n",
    "    word_count = 0\n",
    "    for line in f:\n",
    "        if line.split()[0] == '_BOOK_TITLE_':\n",
    "            key = ''.join(line.strip('\\n'))\n",
    "            key = key.split('___')[1].split('.')[0].replace('_',' ')\n",
    "            fb_text[key] = {'text':[]}\n",
    "        else:\n",
    "            fb_text[key]['text'] += line.strip('\\n').split()\n",
    "        \n",
    "        line_count += 1\n",
    "        word_count += len(line.split())\n",
    "\n",
    "    print('total lines: {}'.format(line_count))\n",
    "    print('total words: {}'.format(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed\n",
    "for k,v in fb_text.items():\n",
    "    text_emb = np.zeros((200,len(v['text'])))\n",
    "    for t in range(len(v['text'])):\n",
    "        text_emb[:,t] = gl_embed.get(v['text'][t],gl_embed['unk'])\n",
    "    v['embedded'] = text_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Miles Davis' *Kind of Blue*\n",
    "\n",
    "The data was obtained by purchasing the album and converting the files to wav."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools for MFCC embedding of jazz and vocal performance\n",
    "import librosa as lbr\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_dir = None # replace with path to directory containing .wav files\n",
    "\n",
    "md_files = os.listdir(uk_dir)\n",
    "md_out = {}\n",
    "for f in md_files:\n",
    "    if '.wav' in f:\n",
    "        name = f.split('.')[0]\n",
    "        md_out[name] = {}\n",
    "        path = md_dir+f\n",
    "        y,sr = lbr.load(path,sr = 32000)\n",
    "        mfc = lbr.feature.mfcc(y,sr=sr)\n",
    "        md_out[name]['data'] = mfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Oum Kalthoum\n",
    "\n",
    "The data consists of the following tracks, which were purchased and converted to wav. All are available, for example, in high-quality remastered format on iTunes.\n",
    "\n",
    "- We Maret El Ayam Daret El Ayam\n",
    "- Seret El Hob\n",
    "- Alf Leila We Leila\n",
    "- Amal Hayate\n",
    "- El Ward Gamel\n",
    "- Fakarony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_dir = None # replace with path to directory containing .wav files\n",
    "\n",
    "uk_files = os.listdir(uk_dir)\n",
    "uk_out = {}\n",
    "for f in uk_files:\n",
    "    if '.wav' in f:\n",
    "        name = f.split('.')[0]\n",
    "        uk_out[name] = {}\n",
    "        path = uk_dir+f\n",
    "        y,sr = lbr.load(path,sr = 32000)\n",
    "        mfc = lbr.feature.mfcc(y,sr=sr)\n",
    "        uk_out[name]['seq'] = mfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. MusicNet and Bach's *Cello Suite 4*\n",
    "\n",
    "Code and data for MusicNet are available at https://homes.cs.washington.edu/~thickstn/start.html\n",
    "\n",
    "We require both the raw data in `musicnet.npz` as well as the metadata file `musicnet_metadata.csv`.\n",
    "\n",
    "The embeddings are obtained from a reduced version of the model implemented in `musicnet_module.ipynb`, which is available at https://github.com/jthickstun/pytorch_musicnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bach_cello_id = [str(x) for x in range(2293,2299)]\n",
    "\n",
    "train_data_path = None # replace with path to musicnet.npz file\n",
    "train_data = np.load(open(train_data_path,'rb'))\n",
    "bach_cello = {}\n",
    "for b in bach_cello_id:\n",
    "    bach_cello[b] = {'seq':train_data[b][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_piece(seq): # embed using convolutional features of learned model\n",
    "    T = len(seq)\n",
    "    starts = np.arange(0,T-window,window)\n",
    "    N = len(starts)\n",
    "    \n",
    "    embedded = torch.zeros((k,regions*N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        x = seq[starts[i]:starts[i]+window]\n",
    "        x = torch.FloatTensor(np.expand_dims(x,0)).cuda()\n",
    "        zx = conv1d(x[:,None,:], model.wsin_var, stride=stride).pow(2) \\\n",
    "           + conv1d(x[:,None,:], model.wcos_var, stride=stride).pow(2)\n",
    "        embedded[:,i*regions:(i+1)*regions] = np.log(zx[0,:,:]+eps)\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block assumes that a MusicNet model has been trained and is available to be loaded. As described in the Supplement, the model we train follows exactly the code in `musicnet_module.ipynb`, with the single exception that we reduce the size of the hidden representation to `k=200`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 2**14\n",
    "eps = 10e-8\n",
    "model_path = None # replace with path to trained model\n",
    "\n",
    "with open('model_path', 'rb') as f:\n",
    "    model = torch.load(model_path)\n",
    "\n",
    "for b in bach_cello.keys(): # intermediate embedded CSV files\n",
    "    print b\n",
    "    seq = bach_cello[b]['seq']\n",
    "    emb = embed_piece(seq).data.numpy()\n",
    "    f = 'bach_cello_'+b+'.csv'\n",
    "    np.savetxt(f,emb,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather files\n",
    "bach = {}\n",
    "for f in fi_fugue+fi_cello:\n",
    "    bfile = '../data/bach/'+f\n",
    "    ix = f[5:-4]\n",
    "    hid = np.loadtxt(bfile,delimiter=',')\n",
    "    tf = np.isnan(hid).any()\n",
    "    if not np.isnan(hid).any():\n",
    "        bach[ix] = {'data':hid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add metadata\n",
    "path_to_metadata = None # replace with path to musicnet_metadata.csv file\n",
    "mn_meta = np.genfromtxt(path_to_metadata,dtype=None,delimiter=',',skip_header=1,usecols=(0,1,2,3,8))\n",
    "bach_meta = [x for x in mn_meta if x[1].decode('UTF-8').strip('\\\"')=='Bach']\n",
    "for bm in bach_meta:\n",
    "    for k in bach.keys():\n",
    "        if str(bm[0]) in k:\n",
    "            bach[k]['meta'] = bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange into single sequence, with correct order of pieces\n",
    "csuite = np.empty((200,0))\n",
    "mvment = 1\n",
    "while mvment < 7:\n",
    "    for k,v in bach.items():\n",
    "        if 'cello' in k:\n",
    "            if int(v['meta'][3].decode('UTF-8').strip('\\\"')[0])==mvment:\n",
    "                print('Adding {}. Shape = {} x {}'.format(v['meta'][3],v['data'].shape[0],v['data'].shape[1]))\n",
    "                csuite = np.hstack((csuite,v['data']))\n",
    "                mvment += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
